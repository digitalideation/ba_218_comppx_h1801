---
layout: inner
---

## Intro

This week will be mostly about planning and inspirations. We will go together through the schedule, evaluation criteria, talk briefly about the basis of ML and have a look at different examples of ML projects. 

## Resources

+ [NN - Intro videos](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)
+ [NN - Intro text](https://ml4a.github.io/ml4a/neural_networks/)
+ [History - History of Machine Learning](https://cloud.withgoogle.com/build/data-analytics/explore-history-machine-learning/)

## Weekly task

Watch the [serie on RNN](https://www.youtube.com/playlist?list=PLRqwX-V7Uu6aCibgK1PTWWu9by6XFdCfh) from NOC2018 by the [Coding Train](http://thecodingtrain.com). You can skip the part about _'Perceptron'_ (10.2, 10.3) and _'Matrix Math'_ (10.6 ... 10.11). Some helpful links are available at [NOC2018 github page](https://github.com/shiffman/NOC-S18/tree/master/week9) and the source code for the toy NN can be downloaded [here](https://github.com/CodingTrain/Toy-Neural-Network-JS/) (slightly different than the one written in the video)

Next week we will play with the [XOR](https://www.youtube.com/watch?v=188B6k_F9jU), [Doodle](https://www.youtube.com/playlist?list=PLRqwX-V7Uu6Zs14zKVuTuit6jApJgoYZQ) and [Color predictor](https://www.youtube.com/watch?v=KtPpoMThKUs) examples. An online demo of the color predictor is available [here](https://editor.p5js.org/natureofcode/sketches/SkYS8WwjG) together with source code.

The goal is to **start understanding how a simple NN work**. It's ok if some parts (even a lot) are unclear for now, we will go through some code example and play around with the toy NN built by Daniel Shiffman together next week. The example below are written in JS, similar examples written in Python are included in ['Going further'](#going-further) below.

You can also have a look at the proposed [tools](../#tools) and give them a try!

## Going further

+ [History - Longer history of Machine Learning](http://www.andreykurenkov.com/writing/ai/a-brief-history-of-neural-nets-and-deep-learning/)
+ [Math - Essence of Linear Algebra](https://www.3blue1brown.com/essence-of-linear-algebra)
+ [Math - Linear Algebra CheatSheet](https://towardsdatascience.com/linear-algebra-cheat-sheet-for-deep-learning-cd67aba4526c)
+ [NN - From scratch (Python)](https://iamtrask.github.io/2015/07/12/basic-python-network/)
+ [NN - From scratch (Python)](https://towardsdatascience.com/how-to-build-your-own-neural-network-from-scratch-in-python-68998a08e4f6)
+ [NN - From scratch (Processing)](https://medium.com/typeme/lets-code-a-neural-network-from-scratch-part-1-24f0a30d7d62)
+ [NN - Intro](https://ujjwalkarn.me/2016/08/09/quick-intro-neural-networks/)
+ [NN - Visualisation](http://scs.ryerson.ca/~aharley/vis/fc/)
+ [ML - Getting started](https://www.youtube.com/watch?v=I74ymkoNTnw)
