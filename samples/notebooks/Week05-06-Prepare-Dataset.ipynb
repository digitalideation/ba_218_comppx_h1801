{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse and prepare a dataset of abc music notations\n",
    "\n",
    "Download the [Nottingham Dataset](https://github.com/jukedeck/nottingham-dataset) or this [dataset of abc music notation from Henrik Norbeck ](http://norbeck.nu/abc/download.asp) select the 'one big zip file (549 kilobytes).' at the end of the page. \n",
    "\n",
    "If we use the Henrik Norbeck DS the first thing we are going to do is parse all the files and concatenate the text in one 'big' text file.\n",
    "\n",
    "We will train our model using Char-RNN for TF, you can clone it from [https://github.com/sherjilozair/char-rnn-tensorflow](https://github.com/sherjilozair/char-rnn-tensorflow)\n",
    "\n",
    "## ABC Notations\n",
    "\n",
    "We will need some software to work with `abc` and `mid` files, you can install by using on Ubuntu:\n",
    "\n",
    "```\n",
    "$ sudo apt-get install abcmidi timidity\n",
    "```\n",
    "\n",
    "On Mac:\n",
    "\n",
    "\n",
    "```\n",
    "$ brew install abcmidi timidity\n",
    "```\n",
    "\n",
    "For mac user you can also install [easy abc](https://www.nilsliberg.se/ksp/easyabc/) to read the files\n",
    "\n",
    "Hereâ€™s a simple example:\n",
    "\n",
    "```\n",
    "X: 1\n",
    "T:\"Hello world in abc notation\"\n",
    "M:4/4\n",
    "K:C\n",
    "\"Am\" C, D, E, F,|\"F\" G, A, B, C|\"C\"D E F G|\"G\" A B e c\n",
    "```\n",
    "\n",
    "To test the installation we can listen to this by saving the above snippet into a `hello.abc` file and running (Mac and Ubuntu):\n",
    "\n",
    "```\n",
    "$ abc2midi hello.abc -o hello.mid && timidity hello.mid\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gu-ma/Downloads/nottingham-dataset/ABC_cleaned\n",
      "\t- reelsh-l.abc \n",
      "\t- reelsm-q.abc \n",
      "\t- reelsd-g.abc \n",
      "\t- playford.abc \n",
      "\t- waltzes.abc \n",
      "\t- reelsa-c.abc \n",
      "\t- slip.abc \n",
      "\t- reelsr-t.abc \n",
      "\t- reelsu-z.abc \n",
      "\t- jigs.abc \n",
      "\t- morris.abc \n",
      "\t- xmas.abc \n",
      "\t- ashover.abc \n",
      "\t- hpps.abc \n",
      "\n",
      "abc_raw_txt:\n",
      "--\n",
      "\n",
      "X: 1\n",
      "T:Hallowe'en\n",
      "% Nottingham Music Database\n",
      "S:Chris Dewhurst 1983, via PR\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "c/2B/2|\"Am\"A/2^G/2A/2B/2 c/2B/2c/2d/2|\"Am\"e/2d/2e/2f/2 \"D7\"g/2e/2d/2B/2|\\\n",
      "\"G\"GB/2G/2 d/2G/2B/2d/2|g/2e/2d/2B/2 G/2A/2B/2G/2|\n",
      "\"Am\"A/2^G/2A/2B/2 c/2B/2c/2d/2|\"Am\"e/2d/2e/2f/2 \"D7\"g/2e/2d/2B/2|\\\n",
      "\"G\"G/2A/2B/2G/2 \"E7\"e/2d/2c/2B/2|\"Am\"cA A::\n",
      "c/2B/2|\"Am\"Aa/2A/2 g/2A/2f/2A/2|\"Am\"e/2d/2e/2f/2 \"D7\"g/2e/2d/2B/2|\\\n",
      "\"G\"GB/2G/2 d/2G/2B/2d/2|\"G\"g/2e/2d/2B/2 G/2A/2B/2G/2|\n",
      "\"Am\"Aa/2A/2 g/2A/2f/2A/2|\"Am\"e/2d/2e/2f/2 \"D7\"g/2e/2d/2B/2|\\\n",
      "\"G\"G/2A/2B/2G/2 \"E7\"e/2d/2c/2B/2|\"Am\"cA A:|\n",
      "\n",
      "\n",
      "X: 2\n",
      "T:Hannah Onestep\n",
      "% Nottingham Music Database\n",
      "S:Pauline Wilson, via PR\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "\"G\"D4|\"D7\"B3F|\"G\"AG FG-|G3F|AG FA-|AG E2|\"Am\"F4-|\"D7\"F4|\"Am\"E4|\n",
      "\"E7\"c3^G|\"Am\"BA ^GA-|A3E|\"D7\"GF ^EF-|FA2F|\"G\"ED B,D-|\"D7\"D4||\n",
      "\"G\"D4|\"D7\"B3F|\"G\"AG FG-|G3G|\"G7\"AG FG-|GA B2|\"C\"A4-|A4|\"Am\"cB Ac-|\n",
      "\"D7\"cB A2|\"G\"BA GB-|\"Em\"BA G2|\"Am\"GE GB-|\"D7\"B2 B2|\"G\"G4-|G4||\n",
      "\n",
      "\n",
      "X: 3\n",
      "T:Happy Day\n",
      "% Nottingham Music Database\n",
      "S:Bryon Bonnett, via PR\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "DG A|\"G\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# input_folder_fp = '/home/gu-ma/Downloads/hn201809'\n",
    "input_folder_fp = '/home/gu-ma/Downloads/nottingham-dataset/ABC_cleaned'\n",
    "abc_raw_txt = ''\n",
    "abc_all_txt = ''\n",
    "\n",
    "# Parse all files in the input folders\n",
    "for root, subdirs, files in os.walk(input_folder_fp):\n",
    "    print(root)\n",
    "    for filename in files:\n",
    "        file_path = os.path.join(root, filename)\n",
    "        print('\\t- %s ' % filename)\n",
    "        if filename.lower().endswith('.abc'):\n",
    "            with open(file_path, 'r') as f:\n",
    "                abc_raw_txt += f.read()\n",
    "\n",
    "print('\\nabc_raw_txt:\\n--\\n' + abc_raw_txt[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we remove the 'unecessary' parts, clean up the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "abc_raw_txt:\n",
      "--\n",
      "c/2B/2|\n",
      "c/2B/2|\n",
      "DG A|\n",
      "Bd2^c|\n",
      "ag e_e|\n",
      "ed c2|\n",
      "GA EG|\n",
      "P:A\n",
      "ed |\n",
      "P:B\n",
      "ef/2g/2 |\n",
      "AG |\n",
      "P:A\n",
      "G|\n",
      "P:B\n",
      "e/2f/2|\n",
      "B/2c/2|\n",
      " [2\n",
      "|\n",
      "d/2e/2|\n",
      "d/2d/2|\n",
      "||\n",
      "P:A\n",
      "A/2G/2|\n",
      "P:B\n",
      "a|\n",
      "P:C\n",
      "A/2G/2|\n",
      "c|\n",
      "c|\n",
      ":|\n",
      "c|\n",
      "c|\n",
      "P:A\n",
      "D|\n",
      "P:B\n",
      "G/2A/2|\n",
      "(A/4G/4)|F/2A/2 A/4B/4A/4F/4|G/2B/2 B/4c/4B/4G/4|F/2A/2 e/4f/4e/4d/4|\\\n",
      "c/2A/2 A/4B/4A/4G/4|\n",
      "F/2A/2 A/4B/4A/4F/4|G/2B/2 B/2(3A/4B/4c/4|d/4e/4d/4c/4 A/4B/4A/4G/4|F/2D/2 D/2\\\n",
      ":|\n",
      "(d/4e/4)|f/2d/2 f/2d/2|f/4d/4f/4g/4 a/2a/2|e/4c/4A/4c/4 e/4c/4A/4c/4|\\\n",
      "e/2f/2 g/2a/4g/4|\n",
      "f/2d/2 f/2d/2|f/4d/4f/4g/4 a/2a/2|d/4e/4d/4c/4 A/4B/4A/4G/4|F/2D/2 D/2:|\n",
      "FG |\n",
      "||\n",
      "P:A\n",
      "A/2G/2|\n",
      "[1\n",
      "[2\n",
      "P:B\n",
      "F/2G/2|\n",
      "D|\n",
      "B|\n",
      "e|\n",
      "c/2d/2|\n",
      "|\n",
      "B/2c/2|\n",
      "K:C\n",
      "G/2G/2|\n",
      ":|\n",
      "c/2d/2|\n",
      "P:A\n",
      "e|\n",
      "P:B\n",
      "(3e/2f/2g/2|\n",
      "D/2D/2|\n",
      "Dc BA|\n",
      "d/2^c/2d/2e/2 dD/2D/2|\n",
      "|:D/2D/2|\n",
      "A|\n",
      "f/2g/2|\n",
      "A|\n",
      "|:\n",
      "a/2g/2|\n",
      "E/2F/2|\n",
      ":|\n",
      "c/2d/2|\n",
      "EG B2|\n",
      "P:A\n",
      "A/2G/2|\n",
      "K:G\n",
      "P:B\n",
      "e/2f/2|\n",
      "P:A\n",
      "A/2G/2|\n",
      "K:G\n",
      "P:B\n",
      "e/2f/2|\n",
      "[1\n",
      "K:C\n",
      "P:C\n",
      "K:C\n",
      "P:D\n",
      "|:\n",
      "P:A\n",
      "B/2c/2|\n",
      "P:B\n",
      "B/2c/2|\n",
      "P:A\n",
      "G/2A/2|\n",
      "P:B\n",
      "B/2A/2|\n",
      "P:A\n",
      "E|:\n",
      "P:V\n",
      "|\n",
      "G/2A/2|: |||:\n",
      "e/2f/2|\n",
      "::\n",
      "A|\n",
      "A,|\n",
      "|:d/2e/2|\n",
      "M:4/4\n",
      "L:1/4\n",
      "B3/2B/2 Bc|\n",
      "c/4d/4|\n",
      "z/2|\n",
      "P:A\n",
      "f/2e/2|\n",
      "K:D\n",
      "P:B\n",
      "f|\n",
      "A/2B/2|\n",
      "(3e/2f\n",
      "\n",
      "abc_headers_txt:\n",
      "--\n",
      "X: 1\n",
      "T:Hallowe'en\n",
      "S:Chris Dewhurst 1983, via PR\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "X: 2\n",
      "T:Hannah Onestep\n",
      "S:Pauline Wilson, via PR\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "X: 3\n",
      "T:Happy Day\n",
      "S:Bryon Bonnett, via PR\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "X: 4\n",
      "T:Harum Scarum\n",
      "S:Bryon Bonnett, via PR\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:C\n",
      "X: 5\n",
      "T:The Headlands\n",
      "S:Ronald Cooper via Rosa M, via EF\n",
      "Y:AAB\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:A\n",
      "X: 6\n",
      "T:Hell Broke Loose In Georgia\n",
      "S:via PR\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "X: 7\n",
      "T:Hi-There\n",
      "S:via PR\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:D\n",
      "X: 8\n",
      "T:High Caul Cap\n",
      "S:via PR\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:D\n",
      "X: 9\n",
      "T:Ho Ro My Nut Brown Maiden\n",
      "S:KCC p8, via EF\n",
      "Y:AB\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:C\n",
      "X: 10\n",
      "T:Home From Holm\n",
      "S:Dennis Salter, via PR\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "X: 11\n",
      "T:Hon Ms Fraser\n",
      "S:RSCDS 23/1, via EF\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:Bm\n",
      "X: 12\n",
      "T:Honey Harbour\n",
      "S:via PR\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:A\n",
      "X: 13\n",
      "T:Hosannah\n",
      "S:Chris McDouall, via EF\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "X: 14\n",
      "T:Hot Time\n",
      "S:Kevin Briggs, via EF\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:D\n",
      "X: 15\n",
      "T:H.R.H. The Prince of Wales's Favourite\n",
      "S:Leslie Dolman, via EF\n",
      "Y:AABBCC\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:D\n",
      "X: 16\n",
      "T:Hull's Victory\n",
      "S:via PR\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:F\n",
      "X: 17\n",
      "T:Hull's Victory\n",
      "S:via PR\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Helper function to extract (and delete) chunks of text from abc_raw_text\n",
    "def extract_text(regex, txt, delete):\n",
    "    output = ''\n",
    "    # extract the text\n",
    "    for result in re.findall(regex, txt, re.S):\n",
    "        output += result + \"\\n\"\n",
    "    # delete from the original file\n",
    "    if delete:        \n",
    "        global abc_raw_txt\n",
    "        abc_raw_txt = (re.sub(regex, '', abc_raw_txt, flags=re.S))\n",
    "    # remove empty lines\n",
    "    abc_raw_txt = ''.join([s for s in abc_raw_txt.strip().splitlines(True) if s.strip()])\n",
    "    return output\n",
    "\n",
    "# Helper function to delete selected lines from a text\n",
    "def delete_lines(regex, txt):\n",
    "    txt = (re.sub(regex, '', txt, flags=re.S))\n",
    "    txt = ''.join([s for s in txt.strip().splitlines(True) if s.strip()])\n",
    "    return txt\n",
    "\n",
    "# Extract intro text\n",
    "useless_txt = extract_text(r'(This file.*?- Questions?.[^\\n]*)', abc_raw_txt, True)\n",
    "\n",
    "# Save the file without the intro text\n",
    "abc_all_txt = abc_raw_txt\n",
    "\n",
    "# Delete 'comments'\n",
    "abc_raw_txt = delete_lines(r'\".[^\\n]*', abc_raw_txt)\n",
    "# Delete Lyrics\n",
    "abc_raw_txt = delete_lines(r'%.[^\\n]*', abc_raw_txt)\n",
    "# Delete some more comments\n",
    "abc_raw_txt = delete_lines(r'W:.[^\\n]*', abc_raw_txt)\n",
    "\n",
    "# Extract headers\n",
    "abc_headers_txt = extract_text(r'(X:.*?K:.[^\\n]*)', abc_raw_txt, True)\n",
    "\n",
    "print('\\nabc_raw_txt:\\n--\\n' + abc_raw_txt[:1000])\n",
    "print('\\nabc_headers_txt:\\n--\\n' + abc_headers_txt[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22260\n",
      "363155\n"
     ]
    }
   ],
   "source": [
    "print(len(abc_raw_txt))\n",
    "print(len(abc_raw_txt_headers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have what we need we can save the file to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_raw_fp = os.path.join(input_folder_fp, 'abc_raw.txt')\n",
    "output_all_fp =  os.path.join(input_folder_fp, 'abc_all.txt')\n",
    "output_header_fp =  os.path.join(input_folder_fp, 'abc_headers.txt')\n",
    "\n",
    "with open(output_raw_fp, 'w') as f:\n",
    "    f.write(abc_raw_txt)\n",
    "    \n",
    "with open(output_all_fp, 'w') as f:\n",
    "    f.write(abc_all_txt)\n",
    "    \n",
    "with open(output_header_fp, 'w') as f:\n",
    "    f.write(abc_headers_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our input text file ready we can run it through our RNN, we will use char-rnn for tensorflow, you can download it and install it from [here](https://github.com/sherjilozair/char-rnn-tensorflow) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/gu-ma/Documents/Projects/201809-HSLU-COMPPX/References/char-rnn-tensorflow/data/abc/input.txt'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "charrnn_folder_fp = '/home/gu-ma/Documents/Projects/201809-HSLU-COMPPX/References/char-rnn-tensorflow'\n",
    "\n",
    "# We try with the full text first\n",
    "shutil.move(output_all_fp, os.path.join(charrnn_folder_fp, 'data', 'abc', 'input.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to the directory and run the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
